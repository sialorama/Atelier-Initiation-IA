{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logoisen](./images/logo_isen.png)......................![logosimplon](./images/logo_simplon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TAUX DE DESABONNEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de notre étude consiste à étudier le taux de desabonnement des clients d'une entreprise.\n",
    "\n",
    "Le taux de désabonnement des clients se produit lorsque les clients ou les abonnés cessent de faire affaire avec \n",
    "une entreprise ou un service.\n",
    "\n",
    "Une entreprise veut savoir quels sont les clients qui vont se désabonner en examinant certains des attributs \n",
    "importants et en y appliquant le Machine Learning ou le Deep Learning.\n",
    "\n",
    "Le dataset est assez représentatif, il comporte 10 000 lignes et 14 colonnes.\n",
    "\n",
    "Données traitées dans le dataset :\n",
    "\n",
    "- numéro de ligne\n",
    "\n",
    "- identifiant client\n",
    "\n",
    "- son nom\n",
    "\n",
    "- le score client\n",
    "\n",
    "- son pays (données à encoder)\n",
    "\n",
    "- son sexe ( données à encoder)\n",
    "\n",
    "- son age\n",
    "\n",
    "- tenure \n",
    "\n",
    "- balance \n",
    "\n",
    "- numéro du produit\n",
    "\n",
    "- possède ou non une cb\n",
    "\n",
    "- membre actif\n",
    "\n",
    "- son salaire\n",
    "\n",
    "- sortie \n",
    "\n",
    "\n",
    "On cherche à savoir si le client se désabonne ou pas en fonction des autres critères (variables du dataset).\n",
    "La variable que l'on va étudier est donc \"exited\"\n",
    "on supprimera par la suite les colonnes qui ne sont pas pertinentes pour l'analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy as sp\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.impute import SimpleImputer\n",
    "#from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import PredefinedSplit\n",
    "#from sklearn import linear_model\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from tensorflow.keras import layers, models\n",
    "#import tensorflow as tf\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quoi servent ces bibliothèques : \n",
    "    \n",
    "* **pandas** est une librairie python qui permet de manipuler facilement des données à analyser.\n",
    "\n",
    "* **Scipy** utilise les tableaux et matrices du module NumPy.\n",
    "\n",
    "* Le module **pyplot** de **matplotlib**  sert à créer des graphiques et les personnaliser.\n",
    "(travailler sur les axes, le type de graphique, sa forme et même rajouter du texte).\n",
    "\n",
    "* **Scikit-learn** sert à extraire la structure de données complexes (textes, images), et à les classifier en utilisant des techniques correspondant à l'état de l'art\n",
    "Scikit-learn est une bibliothèque libre Python destinée à l'apprentissage automatique.\n",
    "\n",
    "* **simple imputer** est utilisé pour completer les valeurs manquantes\n",
    "\n",
    "* **LabelEncoder** peut transformer [chien, chat, chien, souris, chat] en [1,2,1,3,2],il \n",
    "à transformer les données.\n",
    "\n",
    "* Le **One-Hot-Encoding**  transforme  le résultat en binaire.\n",
    "\n",
    "* **train_test_split** sert à répartir  aléatoirement les lignes d’une base de données d’un côté ou de l’autre.\n",
    "\n",
    "* **PredefinedSplit**  Validateur croisé fractionné prédéfini.\n",
    "fournit des indices de train / test pour diviser les données en ensembles de train / test à l'aide d'un \n",
    "schéma prédéfini.\n",
    "\n",
    "* **linear model** pour utiliser la regression logistique.\n",
    "\n",
    "* **mean squarred error** sert pour calculer l' erreur quadratique moyenne ( MSE ).\n",
    "\n",
    "* **pca** sert à Calculez les composantes principales de vos données.\n",
    "\n",
    "* random forest classifier : L'algorithme des forêts aléatoires est connu pour être un des classifieurs les plus \n",
    "efficaces « out-of-the-box ».\n",
    "\n",
    "* **Tensorflow** sert à  entraîner et exécuter des réseaux de neurones profonds pour la classification de chiffres \n",
    "manuscrits, pour la reconnaissance d’image, pour le plongement lexical, pour les réseaux de neurones \n",
    "récurrents, pour les modèles ” sequence-to-sequence ” de traduction automatique, pour le traitement naturel du \n",
    "langage, et pour les simulations basées sur les équations aux dérivées partielles.\n",
    "\n",
    "* **sea born** est utilisé pour la data visualisation en complément de matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importation du fichier de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* importation de la librairy pandas.\n",
    "=> librairie python qui permet de manipuler facilement des données à analyser.\n",
    "\n",
    "missions: \n",
    "* Lecture du fichier au format csv grace à la fonction \"pd.read_csv\".\n",
    "* afficher grâce à la fonction .head nos données dataset.\n",
    "* amusez-vous avec les fichiers: Salaire_Experience, Salaire_Level, Startups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test avec le fichier data se trouvant dans le dossier dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test avec Salaire_Experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test avec Salaire_Level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test avec Startups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le résultat attendu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image1](./images/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu des premiers éléments de notre fichier, nous constatons que certaines variables du jeu de données sont numériques\n",
    "et d'autres sont catégorielles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mission :\n",
    "\n",
    "via la fonction info afficher l'ensemble des variables du dataset ainsi que leur type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le résultat que vous devez obtenir:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image2](./images/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction \"isnull\" nous sert déterminer la présence de valeurs manquantes au sein de notre dataset.\n",
    "En rajoutant la fonction \"sum\", on peut comptabiliser ces valeurs manquantes.\n",
    "\n",
    "mission :\n",
    "\n",
    "afficher les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image3](./images/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. traitement des variables catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables catégorielles correspondent aux variables non numériques. Ci-dessous la fonction qui permet d'afficher les variables catégorielles. \n",
    "\n",
    " categorical = [var for var in dataset.columns if dataset[var].dtype=='O']\n",
    "\n",
    "missions :\n",
    "    \n",
    "\n",
    "afficher gràce à la fonction len  : 'il y a 3 variables catégorielles \"\n",
    "    \n",
    "Pour avoir plus de détails sur la fonction len, voici un lien utile:    \n",
    "\n",
    "https://www.w3schools.com/python/ref_func_len.asp \n",
    "\n",
    "et les variables sont :['Nom', 'Pays', 'Sex']\n",
    "    \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données comporte 3 variables qualitatives qu'il va falloir encoder c'est à dire rendre numérique pour pouvoir exploiter les données par la suite.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des variables catégorielles 'Nom', 'Pays', 'Sex'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on importe pour cela la bibliothéque labelencoder.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "=> LabelEncoder** peut transformer [chien, chat, chien, souris, chat] en [1,2,1,3,2],il a transformé les données \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple encodage  de la variable pays : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encodage de la variable 'Pays'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6964ab181eea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pays\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pays\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pays\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "lab = LabelEncoder()\n",
    "dataset[\"Pays\"] = lab.fit_transform(dataset[\"Pays\"])\n",
    "dataset[\"Pays\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A vous de jouer avec les variables 'Nom' et 'Sex'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encodage de la variable 'Nom'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encodage de la variable 'Sex'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nous affichons de nouveau notre dataset via head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre dataset est maintenant entièrement numérique et prêt à être exploité pour la modélisation.\n",
    "Les variables qui étaient catégorielles ont désormais un type Integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./images/categorielle.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, que nos données sont encodées nous pouvons  les visualiser à travers un graphique .\n",
    "Pour cela,  nous pouvons nous pouvons importer la bibliothèque matplotlib (=>sert à créer des graphiques et les personnaliser)\n",
    "grâce aux fonctions hist et show afficher le rendu ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dataset.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le rendu attendu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image4](./images/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vous de jouer!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Définition de nos variables: Notre variable target (Y) est la variable 'Exited' en fonction des autres .\n",
    "\n",
    "Quelques infos :\n",
    "\n",
    "la variable target est la variable que nous devons expliquer ou prédire (Y) ici il s'agit de la colonne \"Exited\" qui indique si le client est actif ou pas.\n",
    "\n",
    "Pour cela nous allons supprimer les données qui ne seront pas utiles pour la suite, puis nous allons définir les différentes matrices X et Y. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des colonnes non exploitables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction drop nous permet de supprimer toutes les colonnes non utiles et de garder ici les colonnes des variables\n",
    "#explicatives\n",
    "X = dataset.drop([], axis=1)\n",
    "X = dataset.drop([\"Exited\", \"num_ligne\", \"ID_Client\", \"Nom\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On ne récupère que la colonne de la variable à étudier \"Exited\"\n",
    "y = dataset['Exited']\n",
    "y = dataset['Exited'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche la taille des matrices X et Y grace à la fonction \"shape\"\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essayer avec la variable \"Target\" Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y correspond à la matrice (tableau) d'une colonne et 10 000 lignes, c'est à dire la variable à expliquer \"Exited\".\n",
    "\n",
    "X correspond à la matrice (tableau) de 10 colonnes et 10 000 lignes, correspondant à nos 10 variables explicatives.\n",
    "\n",
    "Que constatez-vous ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Fractionnement le jeu de données en jeu d'entraînement et jeu de test (20% pour le test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grace à la librairie train_test_split de la bibliothèque sklearn.model_selection,\n",
    "(=> sert à répartir  aléatoirement les lignes d’une base de données d’un côté ou de l’autre.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>test_size = 0.2</u>\n",
    "\n",
    "on va séparer notre jeu de données en jeu d'entraînement (80% de nos données) et en jeu de test(20% de nos données totales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> random_state </u> :\n",
    "\n",
    "comme son nom l'indique, est utilisé pour initialiser le générateur de nombres aléatoires interne, qui décidera de la division des données en indices de train et de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit de vérifier et de valider les données lors de l'exécution du code plusieurs fois. La définition d'un random_state fixe garantira que la même séquence de nombres aléatoires est générée chaque fois que vous exécutez le code. Et à moins qu'il y ait un autre caractère aléatoire présent dans le processus, les résultats produits seront les mêmes que toujours. Cela aide à vérifier la sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#compléter le paramêtre MANQUANT : \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = XXX, random_state = 0)\n",
    "\n",
    "#Affichage des matrices de variables explicatives pour le jeu d'apprentissage et de test.(X_train, X_test)\n",
    "print(X_train)\n",
    "\n",
    "#compléter le paramêtre MANQUANT : Afficher la matrice du jeu de test X_test\n",
    "print(xxx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Standariser le jeu d'entrainement et de test à l'aide de StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données comporte une grande disparité de valeurs. On va donc les standardiser.\n",
    "La standardisation, qui signifie \"centrer réduire\", désigne la conversion des données vers un format standard \n",
    "commun et normalisé.\n",
    "\n",
    "L’objectif de la standardisation est de rendre les données lisibles par l’ordinateur ou de les structurer de \n",
    "sorte qu’un collaborateur puisse les lire et les comprendre. Une fois acquises, les différentes données doivent \n",
    "être standardisées afin d’être exploitées et étudiées uniformément.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération des colonnes de la matrice X pour le jeu d'apprentissage\n",
    "cols = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour plus d'informations concernant StandardScaler, veuillez vous rendre sur le lien suivant:\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#Standardiser les fonctionnalités en supprimant la moyenne et en mettant à l'échelle la variance unitaire\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Que remarquez-vous ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation des données en dataframe, puis affichage du dataframe\n",
    "X_train = pd.DataFrame(X_train, columns=[cols])\n",
    "\n",
    "X_test = pd.DataFrame(X_test, columns=[cols])\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AVANT D'ALLER PLUS LOIN QUELQUES NOTIONS SPECIFIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./images/INDICATEURS.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Création du modèle de régression logistique et entraînement sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de notre étude est de savoir si les clients souhaitant se désabonner sont bien classés ou non. \n",
    "On va commencer notre modélisation par une régression logistique trés utilisée pour les modèles de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La régression logistique est un modèle statistique permettant d’étudier les relations entre un ensemble de variables qualitatives Xi et une variable qualitative Y. Il s’agit d’un modèle linéaire généralisé utilisant une fonction logistique comme fonction de lien. \n",
    "\n",
    "Un modèle de régression logistique permet aussi de prédire la probabilité qu’un événement arrive (valeur de 1) ou non (valeur de 0) à partir de l’optimisation des coefficients de régression. Ce résultat varie toujours entre 0 et 1. Lorsque la valeur prédite est supérieure à un seuil, l’événement est susceptible de se produire, alors que lorsque cette valeur est inférieure au même seuil, il ne l’est pas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la bibliothèque **linear model** est utilisée pour la regression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilsation de la régression logistique sur le jeu d'entraînement.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# instancier le modèle via le solver qui est un algorithme  capable de résoudre des problèmes de logique\n",
    "# nous sommes dans une classification binaire(se désabonner ou pas)\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "print(y_train.shape)\n",
    "# adapter le modèle\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction des résultats du modèle sur l'ensemble du test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la fonction **logreg.predict** pour le calcul de prédictions sur notre jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "#affichage des prédictions sur le jeu de test.\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison de l'accuracy du modèle sur l'ensemble d'apprentissage et l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la performance du modèle sur le jeu d'entraînement et de test.\n",
    "\n",
    "print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy entre nos données d'apprentissage et nos données de jeu de test sont quasi identiques, ce qui \n",
    "signifie que notre modèle a été bien entrainé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage de la matrice de confusion, TP, TN, FP, FN sur le jeu du test en utilisant la fonction confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilisation de la bibliothèque sklearn.metrics afin d'afficher les indicateurs de performance \n",
    "#et affichage de la matrice de confusion\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(conf, cmap='mako', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour plus de détails concernant la bibliothèque relative à la matrice de confusion, veuillez vous rendre sur le lien suivant:\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En apprentissage automatique supervisé, la matrice de confusion est une matrice qui mesure la qualité d'un système de classification. Chaque ligne correspond à une classe réelle, chaque colonne correspond à une classe estimée. La cellule ligne L, colonne C contient le nombre d'éléments de la classe réelle L qui ont été estimés comme appartenant à la classe C1.\n",
    "\n",
    "Un des intérêts de la matrice de confusion est qu'elle montre rapidement si un système de classification parvient à classifier correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Affichage de la matrise de Confusion\n",
    "from IPython.display import IFrame, display\n",
    "filepath =\"mc.png\"\n",
    "\n",
    "#width et height nous permettent de modifier la taille de l'image.\n",
    "IFrame(filepath, width=1000, height=300)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Une autre version d'affichage de l'image.\n",
    "\n",
    "<img src=\"mc.png\" width=\"400\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/mc.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Vous pouvez faire des tests en jouant avec la taille de l'image.\n",
    "\n",
    "IFrame(filepath, width=xxxxx, height=xxxx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la matrice de confusion avec les valeurs associées à chaque classe.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "#[0,O] correspond à la position des vrais positifs (TP) dans la matrice\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "#[1,1] correspond à la position des vrais négatifs (TN) dans la matrice\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "#[0,1] correspond à la position des faux positifs (FP) dans la matrice\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "#[1,0] correspond à la position des faux négatifs (FN) dans la matrice\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "conf = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(conf, cmap='mako', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat attendu est le suivant:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./images/matrice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amusez-vous à changer la couleur de la matrice gràce au lien suivant:\n",
    "\n",
    "https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(conf, cmap='xxxx', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Calcule les métriques de classification (accuracy, classification error, precision, recall, specificity) en utilisant seulement les valeurs de TP, TN, FP, FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "# Impression de l'accuracy\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "# impression du taux d'erreur\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))\n",
    "\n",
    "\n",
    "\n",
    "# impression de la précision\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "\n",
    "print('Precision : {0:0.4f}'.format(precision))\n",
    "\n",
    "# impression du rappel\n",
    "\n",
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Recall or Sensitivity : {0:0.4f}'.format(recall))\n",
    "\n",
    "# impression de la spécificité\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print('Specificity : {0:0.4f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notre modèle est performant puisque nous avons 1542 clients actifs qui ont été bien classés contre 53 inactifs ayant\n",
    "été classés à tort en actifs.**\n",
    "\n",
    "**De même, nous avons 333 clients actifs ayant été classés à tort comme inactifs et 72 clients inactifs ayant été classés\n",
    "à juste titre comme inactifs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour aller plus loin , les méthodes qui peuvent être testées pour améliorer les performances du modèle.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modèle de régression logistique avec PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  modèle de forêt d'arbres décisionnels (Méthode Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  modèle de forêt d'arbres décisionnels (Méthode Random Forest) avec PCA (réduction de dimensionnalité)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modèle par réseaux de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
